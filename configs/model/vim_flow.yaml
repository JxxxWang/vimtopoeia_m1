defaults:
  - encoder: ast
  - _self_

_target_: src.models.surge_flow_matching_module.SurgeFlowMatchingModule

warmup_steps: 0
scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: ${trainer.max_steps}
  eta_min: ${mul:${model.optimizer.lr},1e-2}

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-4
  weight_decay: 0.0

vector_field:
  _target_: src.models.components.transformer.ApproxEquivTransformer
  projection:
    _target_: src.models.components.transformer.LearntProjection
    d_model: ${model.vector_field.d_model}
    d_token: ${model.vector_field.d_model}
    num_params: ${model.num_params}
    num_tokens: 128
    initial_ffn: true
    final_ffn: false
  num_layers: 8
  d_model: 512
  conditioning_dim: ${model.encoder.d_model}
  num_heads: 8
  d_ff: 512
  num_tokens: ${model.vector_field.projection.num_tokens}
  learn_pe: false
  learn_projection: true
  pe_type: none
  pe_penalty: 0.0
  time_encoding: sinusoidal
  projection_penalty: 0.01
  norm: layer
  skip_first_norm: false
  adaln_mode: basic
  zero_init: false
  outer_residual: false

num_params: 73

# training
cfg_dropout_rate: 0.1


rectified_sigma_min: 0.0

# sampling
validation_sample_steps: 50
validation_cfg_strength: 2.0
test_sample_steps: 200
test_cfg_strength: 2.0

# compile model for faster training with pytorch 2.0
compile: true
